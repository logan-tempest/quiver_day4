# -*- coding: utf-8 -*-
"""ANN_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/117d6Guwy1x3I5uCq5JAfHaJNgLEIEM9o
"""

import tensorflow as tf
import os
print("TensorFlow Version:", tf.__version__)

gpus=tf.config.experimental.list_physical_devices('GPU')
if gpus:
  print("no of gpu available:",len(gpus))
  for gpu in gpus:
    print("GPU:",gpu)
else:
  print("No gpu available using cpu.")

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Basic text cleaning
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)
    return text

df = pd.read_csv("spam.csv", encoding="latin-1")[["v1", "v2"]]
df.columns = ["label", "message"]
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

df['message'] = df['message'].apply(clean_text)
from sklearn.feature_extraction.text import TfidfVectorizer
# Convert text to vector using Bag-of-Words
vectorizer = TfidfVectorizer(max_features=300)
X = vectorizer.fit_transform(df['message']).toarray()
y = df['label'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = Sequential([
    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.1
)

loss, accuracy = model.evaluate(X_test, y_test)
print(f"âœ… Test Accuracy: {accuracy:.4f}")

def predict_message_tf(msg):
    msg_clean = clean_text(msg)
    msg_vector = vectorizer.transform([msg_clean]).toarray()
    prediction = model.predict(msg_vector)[0][0]
    return "ðŸ“© Spam" if prediction > 0.5 else "âœ… Not Spam"

print(predict_message_tf("Get laptop free on indian website shop now"))
print(predict_message_tf("Meeting at 5 pm, bring your notes."))

model.save('model.h5')

from tensorflow.keras.models import load_model

# Load the saved model
loaded_model = load_model("model.h5")

def predict_with_loaded_model(msg):
    msg_clean = clean_text(msg)
    msg_vector = vectorizer.transform([msg_clean]).toarray()
    prediction = loaded_model.predict(msg_vector)[0][0]
    return "ðŸ“© Spam" if prediction > 0.5 else "âœ… Not Spam"

# Example usage:
print(predict_with_loaded_model("Get laptop free on indian website shop now."))
print(predict_with_loaded_model("your mom is calling you."))